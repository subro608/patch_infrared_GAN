{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANS2testing",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW9ZaU9kKWQb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBvSXRO3JaND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpwUbu8KqIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorview"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7eZs3r-uCuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import tensorview as tv\n",
        "import tarfile\n",
        "import glob\n",
        "import argparse\n",
        "import os, time, datetime\n",
        "#import PIL.Image as Image\n",
        "from keras.models import load_model, model_from_json\n",
        "from skimage.metrics import peak_signal_noise_ratio,structural_similarity\n",
        "from skimage.io import imread, imsave\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHYyiBxvFwNw",
        "colab_type": "text"
      },
      "source": [
        "Here we download the testing dataset and then convert the images into suitable size using tensorflow functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEaAIB6pAY06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://robotics.ethz.ch/~asl-datasets/flir_17_Sept_2013/asl_eth_flir.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtQRWXNKAjB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip asl_eth_flir.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr4s2wadAmwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaration of list that will contain the testing files\n",
        "files = []\n",
        "\n",
        "#Fetching the files of the images\n",
        "for i in range(5,13):\n",
        "  img_dir = \"flir_17_Sept_2013/Sempach-{}/8bit\".format(i)\n",
        "  data_path = os.path.join(img_dir,'*g')\n",
        "  files_ = glob.glob(data_path)\n",
        "  files.extend(files_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xry5uFqrKlLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Displaying an image from the testing dataset\n",
        "im = cv2.imread(files[0])\n",
        "plt.imshow(im)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7fHFzmeBJCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Printing total number of testing files\n",
        "print(len(files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBl8nSUuBC-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Declaration of list which will hold low res testing images\n",
        "test_data_lr = []\n",
        "#Declaration of list which will hold high res testing images\n",
        "test_data_hr = []\n",
        "\n",
        "def random_crop(img, random_crop_size): \n",
        "    \"\"\"Function used for generating random cropped images\"\"\"\n",
        "    h, w = img.shape[0], img.shape[1] \n",
        "    dy, dx = random_crop_size \n",
        "    x = np.random.randint(0, w-dx + 1) \n",
        "    y = np.random.randint(0, h-dy + 1) \n",
        "    return img[y:(y+dy), x:(x+dx), :] \n",
        "\n",
        " \n",
        "def generate_test_images_1(test_files,test_lr,test_hr):\n",
        "  \"\"\"Generation of images with the help of tensorflow random contrast and resizing functions\"\"\"\n",
        "  for f in test_files:\n",
        "    im = cv2.imread(f)\n",
        "    try:\n",
        "      img_1 = tf.image.resize_with_crop_or_pad(im,256,256)\n",
        "      img_2 = tf.image.random_contrast(img_1,0.2,0.21)   \n",
        "      test_lr.append(np.asarray(img_2))\n",
        "      test_hr.append(np.asarray(img_1))\n",
        "    except:\n",
        "      print('image cannot be displayed')   \n",
        "  return test_lr,test_hr    \n",
        "\n",
        "def generate_test_images_2(test_files,test_lr,test_hr):\n",
        "  \"\"\"Generation of 2048 grayscale images with the help of random contrast and random crop numpy functions\"\"\"\n",
        "  for i in range(2048):\n",
        "    try:\n",
        "      im = cv2.imread(test_files[i])\n",
        "      gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "      gray = gray/255.0\n",
        "      gray = np.expand_dims(gray,axis = -1)  \n",
        "      img_0 = np.concatenate((gray,gray,gray),axis = -1)\n",
        "      img_1 = random_crop(img_0,(256,256))\n",
        "      img_2 = tf.image.random_contrast(img_1,0.2,0.21)\n",
        "      test_hr.append(np.asarray(img_1))\n",
        "      test_lr.append(np.asarray(img_2))\n",
        "    except:\n",
        "      print('cannot display') \n",
        "  return test_lr,test_hr    \n",
        "\n",
        "#test_data_lr,test_data_hr = generate_test_images_2(files,test_data_lr,test_data_hr)\n",
        "test_data_lr,test_data_hr = generate_test_images_1(files,test_data_lr,test_data_hr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRXh969Job6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking the size of low res testing images \n",
        "print(np.asarray(test_data_lr).shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn72aLzwMStc",
        "colab_type": "text"
      },
      "source": [
        "# TRAIN DATASET \n",
        "Downloading the training dataset which is the coco dataset because of less availability of RAM I am using the validation dataset which has 5000 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bbl687XghGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQN75L0gnbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip val2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3ZXrNN17dI3",
        "colab": {}
      },
      "source": [
        "import glob,os\n",
        "img_dir = \"val2017\" \n",
        "data_path = os.path.join(img_dir,'*g')\n",
        "files2 = glob.glob(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "26Jm03Zy7dI8",
        "colab": {}
      },
      "source": [
        "#Printing the number of training files\n",
        "print(len(files2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvwvw0A8Bh9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = []\n",
        "data = []\n",
        "def crop_img(img):\n",
        "  \"\"\"Converting images into grayscale and adding random contrast with the help of tensorflow functions\"\"\"\n",
        "  img_2 = tf.image.random_contrast(img,0.2,0.21)\n",
        "  img_1 = tf.image.rgb_to_grayscale(img)\n",
        "  img_2 = tf.image.rgb_to_grayscale(img_2)\n",
        "  img_1 = tf.concat([img_1,img_1,img_1],axis = -1)\n",
        "  img_2 = tf.concat([img_2,img_2,img_2],axis = -1)\n",
        "  return img_1,img_2\n",
        "\n",
        "def generate_images(files,list1,list2):\n",
        "  \"\"\"Resizing training images and cropping them  \"\"\"\n",
        "  for i in range(5000):\n",
        "    try:\n",
        "      im = cv2.imread(files[i])\n",
        "      im = cv2.resize(im,(128,128),interpolation = cv2.INTER_AREA)\n",
        "      im2,im3 = crop_img(im)\n",
        "      target_img = im2\n",
        "      input_img = im3\n",
        "      list1.append(np.asarray(target_img))\n",
        "      list2.append(np.asarray(input_img))    \n",
        "    except:\n",
        "      print('Cannot work on the image')\n",
        "  return list1,list2\n",
        "\n",
        "data,data2 = generate_images(files2,data,data2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFpQEJeSjA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting the training images list and labels list into numpy arrays\n",
        "data_array = np.asarray(data)\n",
        "data2_array = np.asarray(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daUcBdDhpdmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Printing the shape of training images array\n",
        "print(data_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD54M_5Nxkl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wasserstein_loss(y_true, y_pred):\n",
        "    \"\"\"Code for wasserstein loss function\"\"\"\n",
        "    return -tf.math.reduce_mean(y_true - y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOjIlkkUtZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sub(img_shape,filters = 64):\n",
        "  \"\"\"Generator block where enhanced infrared images are generated\"\"\"\n",
        "  input_img = tf.keras.Input(shape=img_shape)\n",
        "  input_image = tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),strides=2,padding = 'same')(input_img)\n",
        "  c1 = tf.keras.layers.ReLU()(input_image)\n",
        "  p1 = c1\n",
        "  c1 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c1)\n",
        "  c1 = tf.keras.layers.BatchNormalization()(c1)\n",
        "  c2 = tf.keras.layers.ReLU()(c1)\n",
        "  c2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(3,3),strides=1,padding = 'same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.ReLU()(c2)  \n",
        "  u1 = tf.concat([c3,p1],axis = -1)\n",
        "  u2 = tf.keras.layers.Conv2D(filters=filters,kernel_size=(1,1),strides=1)(u1)\n",
        "  u3 = tf.keras.layers.Conv2DTranspose(filters = 3,kernel_size=(4,4),strides = 2,padding = 'same')(u2)\n",
        "  u4 = tf.keras.activations.tanh(u3)\n",
        "  gen_sub = tf.keras.Model(input_img,u4)\n",
        "  return gen_sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxLG2PkZchuf",
        "colab": {}
      },
      "source": [
        "def disc_sub(img_dim,filters = 64):\n",
        "  \"\"\"Discriminator block where generated images are discriminated against the given images\"\"\"\n",
        "  input_src_img = tf.keras.Input(shape = img_dim)\n",
        "  input_target_img = tf.keras.Input(shape = img_dim)\n",
        "  merged = tf.keras.layers.Concatenate()([input_src_img,input_target_img])\n",
        "  c1 = tf.keras.layers.Conv2D(filters = filters,kernel_size=(4,4),strides=2,padding='same')(merged)\n",
        "  c2 = tf.keras.layers.LeakyReLU()(c1)\n",
        "  c2 = tf.keras.layers.Conv2D(filters = filters*2,kernel_size=(4,4),strides=2,padding='same')(c2)\n",
        "  c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "  c3 = tf.keras.layers.LeakyReLU()(c2)\n",
        "  c3 = tf.keras.layers.Conv2D(filters = filters*4,kernel_size=(4,4),strides=2,padding='same')(c3)\n",
        "  c3 = tf.keras.layers.BatchNormalization()(c3)\n",
        "  c4 = tf.keras.layers.LeakyReLU()(c3)\n",
        "  c4 = tf.keras.layers.Conv2D(filters = filters*8,kernel_size=(4,4),strides=1,padding='same')(c4)\n",
        "  c4 = tf.keras.layers.BatchNormalization()(c4)\n",
        "  c5 = tf.keras.layers.LeakyReLU()(c4) \n",
        "  c6 = tf.keras.layers.Conv2D(filters = 1,kernel_size=(4,4),strides=1,padding='same')(c5)\n",
        "  c7 = tf.keras.activations.sigmoid(c6)\n",
        "  disc = tf.keras.Model([input_src_img,input_target_img],c7)\n",
        "  optim = tf.keras.optimizers.Adagrad(learning_rate = 0.002)\n",
        "  disc.compile(loss = wasserstein_loss,optimizer = optim,loss_weights = [0.5])\n",
        "  return disc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhS-8Qc2kqs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def patch_gan(g_model, d_model, image_shape):\n",
        "\t\"\"\"Here we finally combine the generator and discriminator blocks into a single model\"\"\"\n",
        "\td_model.trainable = False\n",
        "\tin_src = tf.keras.Input(shape=image_shape)\n",
        "\tgen_out = g_model(in_src)\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        "\tmodel = tf.keras.Model(in_src, [dis_out, gen_out])\n",
        "\topt = tf.keras.optimizers.RMSprop(lr=0.2)\n",
        "\tmodel.compile(loss=[wasserstein_loss, 'mae'], optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZusCLGR-krCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the input image shape\n",
        "img_dim = (128,128,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQB43GNokrAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating an object of the discriminator block\n",
        "disc_model = disc_sub(img_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH1y5WNukqwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summary of the architecture of the discriminator block \n",
        "disc_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-GWMVg7kqrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating an object of the generator block\n",
        "generator_model = gen_sub(img_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwKwVDDkqoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating an object of the patch gan block\n",
        "patchgan_model = patch_gan(generator_model, disc_model, img_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5N8aooDkqh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summary of whole model architecture\n",
        "patchgan_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5N3QNRiUfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.asarray(data_array)\n",
        "y_train = np.asarray(data2_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33YWg7dP_0Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Printing the shape of the high resolution y_train images\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVrE7rSlTCjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting the patch size to 32\n",
        "patch = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvMmDSaH2C07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting the batch size and number of critics\n",
        "batch_size = 32\n",
        "n_critic = x_train.shape[0]//batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgeuHNNkhe5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here we finally train the model and set the number of epochs \n",
        "n_critic = x_train.shape[0]//batch_size\n",
        "clip_value = 0.01\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "  for i in range(n_critic):\n",
        "    batch_image = x_train[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "    batch_noise = y_train[i*batch_size:(i+1)*batch_size]\n",
        "    batch_gen_image = generator_model.predict(batch_noise)\n",
        "\n",
        "    d_loss_real = disc_model.train_on_batch([batch_image,batch_noise],np.ones((batch_size,patch,patch,1)))\n",
        "    d_loss_fake = disc_model.train_on_batch([batch_image,batch_gen_image],np.zeros((batch_size,patch,patch,1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real,d_loss_fake)\n",
        "    for l in disc_model.layers:\n",
        "      weights = l.get_weights()\n",
        "      weights = [np.clip(w,-clip_value,clip_value) for w in weights]\n",
        "      l.set_weights(weights)\n",
        "\n",
        "    disc_model.trainable = False\n",
        "    g_loss,_,_ = patchgan_model.train_on_batch(batch_noise,[np.ones((batch_size,patch,patch,1)),batch_image])\n",
        "    disc_model.trainable = True\n",
        "\n",
        " \n",
        "  print(\"epoch {} and loss {} \".format(epoch,g_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRz4OD4F0ZXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def compute_psnr(img1, img2):\n",
        "  \"\"\"Here we calculate the psnr between the generated and the given image\"\"\"\n",
        "  img1 = img1.astype(np.float64) / 255.\n",
        "  img2 = img2.astype(np.float64) / 255.\n",
        "  mse = np.mean((img1 - img2) ** 2)\n",
        "  if mse == 0:\n",
        "    return \"Same Image\"\n",
        "  return 10 * math.log10(1. / mse)\n",
        "def psnr_test(test_LR,test_HR):\n",
        "  \"\"\"Here we take the generated image and\\\\\n",
        "   compute its PSNR with respect to the \n",
        "   given image and return the psnr value\"\"\"\n",
        "   \n",
        "  image_ = test_LR\n",
        "  image_gen_ = generator_model.predict(image_)\n",
        "  psnr_result = compute_psnr(np.asarray(image_gen_),test_HR)\n",
        "  return psnr_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AO7OAcuZBbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_model.save(\"generator_model1000.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7gIeKG5DedJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_ = generator_model.predict(np.asarray(test_data_lr[256:1024]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmY6pTQNECg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "peak_signal_noise_ratio(np.asarray(test_data_hr[256:1024]),image_gen_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuZ7Umhlcf_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}